from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from core.config import DB_PATH_V3, EMBEDDING_MODEL_NAME, COLLECTION_NAME
import torch

class VectorDBManager:
    """
    å•ä¾‹æ¨¡å¼ç®¡ç†æ•°æ®åº“è¿æ¥ï¼Œé˜²æ­¢é‡å¤åŠ è½½æ¨¡å‹å¯¼è‡´å†…å­˜çˆ†ç‚¸
    """
    _instance = None
    _vector_store = None

    @classmethod
    def get_vector_store(cls):
        if cls._vector_store is None:
            print(f"ğŸ”„ [Retriever] æ­£åœ¨åˆå§‹åŒ–å‘é‡åº“: {DB_PATH_V3}")
            try:
                if torch.backends.mps.is_available():
                    device = "mps"
                elif torch.cuda.is_available():
                    device = "cuda"
                else:
                    device = "cpu"
                embeddings = HuggingFaceEmbeddings(
                    model_name=EMBEDDING_MODEL_NAME,
                    model_kwargs={'device': device},
                    encode_kwargs={'normalize_embeddings': True}
                )
                # âš ï¸ collection_name å¿…é¡»å’Œä½  ingest å…¥åº“æ—¶çš„ä¸€è‡´ï¼
                # ä¹‹å‰æˆ‘ä»¬ç”¨çš„æ˜¯ "recipe_collection_v3"
                cls._vector_store = Chroma(
                    collection_name=COLLECTION_NAME, 
                    embedding_function=embeddings,
                    persist_directory=DB_PATH_V3
                )
                print("âœ… [Retriever] å‘é‡åº“åŠ è½½å®Œæˆ")
            except Exception as e:
                print(f"âŒ [Retriever] æ•°æ®åº“åŠ è½½å¤±è´¥: {e}")
                return None
        return cls._vector_store

# def retrieve_docs(query: str, top_k: int = 4, score_threshold: float = 0.8):
#     """
#     æ£€ç´¢æ ¸å¿ƒå‡½æ•°
#     :param query: ç”¨æˆ·é—®é¢˜
#     :param top_k: è¿”å›å‡ æ¡ç»“æœ
#     :param score_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ (è¶Šä½è¶Šä¸¥æ ¼, >0.8 é€šå¸¸å°±ä¸å¤ªç›¸å…³äº†)
#     """
#     db = VectorDBManager.get_vector_store()
#     if not db:
#         return []

#     # æ‰§è¡Œæ£€ç´¢
#     results = db.similarity_search_with_score(query, k=top_k)
    
#     # æ ¼å¼åŒ–ç»“æœ
#     filtered_results = []
#     for doc, score in results:
#         # è¿‡æ»¤æ‰ä¸å¤ªç›¸å…³çš„ç»“æœ (åˆ†æ•°è¶Šä½è¶Šå¥½)
#         if score <= score_threshold:
#             filtered_results.append({
#                 "name": doc.metadata.get('name', 'æœªçŸ¥'),
#                 "tags": doc.metadata.get('tags', ''),
#                 "image": doc.metadata.get('image', ''),
#                 "content": doc.page_content,
#                 "score": score
#             })
            
#     return filtered_results
# ... (å‰é¢çš„å¼•ç”¨ä¸å˜)

def retrieve_docs(query: str, top_k: int = 4, score_threshold: float = 0.8):
    """
    æ£€ç´¢æ ¸å¿ƒå‡½æ•°
    """
    db = VectorDBManager.get_vector_store()
    if not db:
        return []

    # æ‰§è¡Œæ£€ç´¢
    results = db.similarity_search_with_score(query, k=top_k)
    
    # æ ¼å¼åŒ–ç»“æœ
    filtered_results = []
    for doc, score in results:
        # è¿‡æ»¤æ‰ä¸å¤ªç›¸å…³çš„ç»“æœ
        if score <= score_threshold:
            filtered_results.append({
                "id": doc.metadata.get('id', ''),          # å»ºè®®åŠ ä¸Š ID
                "name": doc.metadata.get('name', 'æœªçŸ¥'),
                "tags": doc.metadata.get('tags', ''),
                "image": doc.metadata.get('image', ''),
                
                # âœ…ã€æ–°å¢å…³é”®ä¿®æ”¹ã€‘æå–æ­¥éª¤æ•°æ®
                "instructions": doc.metadata.get('instructions', []), 
                
                "content": doc.page_content,
                "score": score
            })
            
    return filtered_results